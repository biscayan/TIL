# DANN experiment
- train set : (1) 100시간(80000개의 파일)의 source domain data (2) 25시간(20000개의 파일)의 target domain data  
- train set의 target domain data는 domain classifier에서만 사용이 됨, label predictor에서는 사용되지 않음  
- validation set : 3시간(2000개의 파일)의 target domain data  
- test set : 3시간(2000개의 파일)의 target domain data  
- procedure : [label predictor] 4 CNN layers -> 1 FC layer -> 4 BiGRU layers -> 1 FC layer -> CTC -> label (A-Z, space, apostrophe)  
              [domain classifier] 4 CNN layers -> 1 FC layer -> 4 FC layers -> CrossEntropy -> domain (standard or heavy accent)  
- feature : 128 mel spectrograms  
- rnn dim : 512  
- learning rate : 0.0001  
- batch size : 32  
- domain adaptation parameter : 0.01  

## Australia accent
- test loss : 1.251394  
- CER : 33.14%  
- WER : 73.49%  

## Canada accent
- test loss : 0.683107  
- CER : 19.17%  
- WER : 53.34%  

## England accent
- test loss : 1.178682  
- CER : 31.94%  
- WER : 72.09%   

## India accent
- test loss : 1.563021  
- CER : 42.14%  
- WER : 82.73%  