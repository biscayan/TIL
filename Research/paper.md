# Paper
The paper list what I read
## Paper list
### Machine Learning & Deep Learning
- A Survey on Deep Transfer Learning
- An overview of Multi-Task Learning in Deep Neural Networks
- Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
- Distilling the Knowledge in a Neural Network
- Domain-Adversarial Training of Neural Networks
- Generative Adversarial Nets
- Layer Normalization
- Long-short Term Memory
- Representation Learning with Contrastive Predictive Coding
### Speech Recognition
- A deep Learning Approach to Automatic Characterisation of Rhythm in Non-native English Speech
- Adaptation Methods for Non-native Speech
- Adversarial Learning of Raw Speech Features for Domain Invariant Speech Recognition
- Adversarial Multi-task Learning of Deep Neural Networks for Robust Speech Recognition
- Adversarial Training for Multilingual Acoustic Modeling
- An overview of Automatic Speech Attribute Transcription (ASAT)
- An overview of End-to-end Automatic Speech Recognition
- A time delay neural network architecture for efficient modeling of long temporal contexts
- Audio Augmentation for Speech Recognition
- Automatic Speech Recognition for Second Language Learning: How and Why It Actually Works
- Automatic Speech Recognition of Multiple Accented Englsih Data
- Common Voice: A Massively-Multilingual Speech Corpus
- Computer-Assisted Pronunciation Training from Pronunciation Scoring Towards Spoken Language Learning
- Conformer: Convolution-augmented Transformer for Speech Recognition
- Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks
- ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context
- Coupled Training of Sequence-to-sequence Models for Accented Speech Recognition
- Data Augmentation Improves Recognition of Foreign Accented Speech
- Deep Speech2: End-to-end Speech Recognition in English and Mandarin
- Domain Adversarial Training for Accented Speech Recognition
- End-to-end Accented Speech Recognition
- ESPnet: End-to-end Speech Processing Toolkit
- Exploring Deep Learning Architectures for Automatically Grading Non-native Spontaneous Speech
- Exploring Lexicon-Free Modeling Units for End-to-End Korean and Korean-English Code-Switching Speech Recognition
- Improved Accented Speech Recognition using Accent Embeddings and Multi-task Learning
- Introducing Attribute Features to Foreign Accent Recognition
- Jasper: An End-to-End Convolutional Neural Acoustic Model
- Joint CTC-attention based end-to-end speech recognition using multi-task learning
- Language identification with suprasegmental cues: A study based on speech resynthesis
- Leveraging Native Language Information for Improved Accented Speech Recognition
- Librispeech: An ASR Corpus Based on Public Domain Audio Books
- Listen, Attend and Spell
- MLLR-based Accent Model Adaptation without Accented Data
- Multi-accent Speech Recognition with Hierarchical Grapheme Based Models
- Multi-dialect Speech Recognition with A Single Sequence-to-sequence Model
- Multi-task Learning for Speech Recognition: An overview
- PyKaldi: A Python Wrapper for Kaldi
- PyKaldi2: Yet Another Speech Toolkit Based on Kaldi and Pytorch
- Quartznet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions
- Sequence Transduction with Recurrent Neural Networks
- Some Commonly Used Speech Feature Extraction Algorithms
- SpecAugment: A simple Data Augmentation Method for Automatic Speech Recognition
- Speech Augmentation using Wavenet in Speech Recognition
- Speech Recognition of Multiple Accented English Data Using Acoustic Model Interpolation
- Speech recognition with weighted finite-state transducers
- Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition
- The Kaldi Speech Recognition Toolkit
- The Pytorch-kaldi Speech Recognition Toolkit
- Using Accent-Spercific Pronunciation Modelling for Robust Speech Recognition
- vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations
- wav2vec: Unsupervised Pre-training for Speech Recognition
- wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations
- Word Beam Search: A connectionist Temporal Classification Decoding Algorithm
- 저자원 환경의 음성인식을 위한 자기 주의를 활용한 음향 모델 학습
### Speaker Recognition
- Deep Learning Methods in Speaker Recognition: A Review
- Deep speaker: an end-to-end neural speaker embedding system
- Speaker Recognition Based on Deep Learning: An Overview
- Unsupervised Domain Adaptation via Domain Adversarial Training for Speaker Recognition
### Speech Enhancement
- Improved Speech Enhancement with the Wave-U-Net
- SEGAN: Speech Enhancement Generative Adversarial Network
### Speech Synthesis
- A review of deep learning based speech synthesis
- Adversarial Audio Synthesis
- Emotional Speech Synthesis With Rich And Granularized Control
- Natural tts synthesis by conditioning wavenet on mel spectrogram predictions
- Tacotron: Towards end-to-end speech synthesis
- Waveglow: A flow-based generative network for speech synthesis
- Wavenet: A Generative Model for Raw Audio
### Natural Language Processing
- An algorithm for suffix stripping
- Attention is all you need
- BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension
- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
- Big Bird: Transformers for Longer Sequences
- Electra: Pre-training text encoders as discriminators rather than generators
- Language Models are Unsupervised Multitask Learners
### Computer vision
- Albumentations: fast and flexible image augmentations
- Deep residual learning for image recognition
- EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
- Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks
- Rich feature hierarchies for accurate object detection and semantic segmentation
- U-Net: Convolutional Networks for Biomedical Image Segmentation
- Very deep convolutional networks for large-scale image recognition
- You Only Look Once: Unified, Real-Time Object detection
### Reinforcement Learning
- Neural architecture search with reinforcement learning
### Linguistics
- Accent as a Social Symbol
- Calibrating rhythm: First language and second language studies
- Control Methods Used in a Study of the Vowels
- Correlates of linguistic rhythm in the speech signal
- Durational Variability in Speech and the Rhythm Class Hypothesis
- History of ESL Pronunciation Teaching
- Intonation
- Language Discrimination by Newborns: Toward an Understanding of the Role of Rhythm
- Measures of Native and Non-Native Rhythm in a Quantity Language
- On the distinction between 'stress-timed' and 'syllable-timed' languages
- On the Historical Phonotactic of English
- Relations between language rhythm and speech rate
- Stress-timing and Syllable-timing Reanalyzed
- Sound Change And Syllable Structure in Germanic Phonology
- Speech rhythm across turn transitions in cross-cultural talk-in-interaction
- The Environment for Open-syllable Lengthening in Middle English
- The Historical Evolution of English Pronunciation
- The Original ToBI System and the Evolution of the ToBI Framework
- The Past, Present and Future of English Rhythm
- Voice Onset Time (VOT) at 50: Theoretical and practical issues in measuring voicing distinctions
- 그림의 법칙: 연쇄 밀기 입장과 연쇄 당김 입장